# -*- coding: utf-8 -*-
"""train.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rXggQjeT_ZbmSg2opJYwRX5JVqh9s6Qu
"""

# Load the Drive helper and mount
#from google.colab import drive
#mounted_path_folder = '/content/drive'
#drive.mount(mounted_path_folder, force_remount=True)

import pandas as pd
import numpy as np
#import matplotlib.pyplot as plt
from scipy.stats import zscore
#import seaborn as sns
import pickle
#from sklearn.decomposition import PCA
import os

from sklearn.preprocessing import OneHotEncoder, FunctionTransformer
from sklearn.ensemble import RandomForestClassifier 
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LinearRegression, LogisticRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.compose import ColumnTransformer
from sklearn.impute import SimpleImputer
from sklearn.pipeline import Pipeline
from sklearn.model_selection import train_test_split
from sklearn.model_selection import cross_val_score

path_folder = "" #os.getcwd()
#path_folder = "/content/drive/MyDrive/dsprojects/dsproject_nyc_traffic" # parent of current src folder

path_folder_traffic_landuse_street_segment_data= path_folder + "../data/temp/traffic_landuse_street_segment_data.csv"

traffic_landuse_street_segment_data_orig = pd.read_csv(path_folder_traffic_landuse_street_segment_data)

traffic_landuse_street_segment_data_orig["Traffic"] = (traffic_landuse_street_segment_data_orig["Traffic"].apply(np.log1p))
#traffic_landuse_street_segment_data_orig["Traffic"] = zscore(traffic_landuse_street_segment_data_orig["Traffic"], axis=0)
# DO NOT ZSCORE SO THAT IT IS REVERSIBLE

traffic_zscore = dict()
traffic_zscore["mean"] = np.mean(traffic_landuse_street_segment_data_orig["Traffic"])
traffic_zscore["std"] = np.std(traffic_landuse_street_segment_data_orig["Traffic"], ddof=0)



with open(path_folder +'../data/temp/saved_zscore_traffic.pkl', 'wb') as f:
    pickle.dump(traffic_zscore, f)
    f.close()

assert False;

cols = [ 'Hour_0','Hour_1','Hour_2','Hour_3','Hour_4','Hour_5','Hour_6','Hour_7','Hour_8','Hour_9','Hour_10','Hour_11','Hour_12','Hour_13','Hour_14','Hour_15','Hour_16','Hour_17','Hour_18','Hour_19','Hour_20','Hour_21','Hour_22','Hour_23',
]
cols += ['LandUse_01', 'LandUse_02', 'LandUse_03', 'LandUse_04', 'LandUse_05', 'LandUse_06', 'LandUse_07', 'LandUse_08', 'LandUse_09', 'LandUse_10', 'LandUse_11', 'LandUse_NULL']
cols += ['Number_Tra'] # 83
cols += ['StreetWidt'] # 87
cols += ['is_weekend'] # 90

#cols += ['month_1','month_10','month_11','month_12','month_2','month_3','month_4','month_9']
#cols += ['UnitsRes']
#cols += ['RW_TYPE_1'] 
#cols += ['RW_TYPE_2']
#cols += ['NonPed_V']
#cols += ['ResArea']

categ_columns = []
numer_columns = cols
MODEL_INPUT_DF_OUTPUT_COLUMN = "Traffic"
MODEL_INPUT_DF_INPUT_COLUMNS = categ_columns + numer_columns
## creating the baseline model pipeline


categ_columns_pipeline = Pipeline([
    ("imp", SimpleImputer(strategy="constant", fill_value="NULL")),
    ("one-hot", OneHotEncoder(sparse=True,handle_unknown="ignore")),
])

numer_columns_pipeline = Pipeline([
    ("imp", SimpleImputer(strategy="constant", fill_value=0))
    
])


ct0 = ColumnTransformer([
    ("categ",categ_columns_pipeline,categ_columns),
    ("numer",numer_columns_pipeline,numer_columns)
])

## Implementing Random Forest Classification
## MODEL = RandomForestClassifier(class_weight="balanced")
## Or more simpler Decision Tree Classification

MODEL = LinearRegression()
MODEL = DecisionTreeRegressor()

PCA_PHASE = PCA(2)
pl_model = Pipeline([
        ("features", ct0),
        ("model", MODEL)
])

y = traffic_landuse_street_segment_data_orig[MODEL_INPUT_DF_OUTPUT_COLUMN]#>0
X = traffic_landuse_street_segment_data_orig[MODEL_INPUT_DF_INPUT_COLUMNS]

np.random.seed(1)
X_train, X_test, y_train, y_test = train_test_split(X,y)
pl_model.fit(X_train, y_train)
np.random.seed(1)
print("Cross val score:", cross_val_score(pl_model, X_train, y_train, cv=4))
print("Score:", pl_model.score(X_test, y_test))


with open(path_folder +'../data/final/dtr.pkl', 'wb') as f:
    pickle.dump(pl_model, f)
    f.close()
